{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos baseados em árvores\n",
    "\n",
    "<br>\n",
    "\n",
    "Ao longo do módulo, discutimos bastante as árvores de decisão, bem como ensemble de árvores, como Random Forest e algoritmos do tipo boosting.\n",
    "\n",
    "Esses __ensembles acabam tendo muitos hiperparâmetros;__ escolhe-los de forma manual acaba sendo muito custoso e tedioso. \n",
    "\n",
    "Neste exercício, vamos discutir a respeito da metolodia __grid-search__, que otimiza essa busca de hiperparâmetros.\n",
    "\n",
    "Considere o dataset abaixo (basta executar as células):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 10) (111, 10) (331,) (111,)\n"
     ]
    }
   ],
   "source": [
    "#problema de regressão\n",
    "\n",
    "X, y = load_diabetes().data, load_diabetes().target\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "print(Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine que queremos testar - usando cross-validation - várias instâncias de Random Forests: com 10 árvores, com 100 árvores, com 1000 árvores, com profundidade máxima 1, 5, 10. \n",
    "\n",
    "Como podemos proceder? O código abaixo exemplifica um jeito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimators:  10  prof:  1  | R2 mean / std:  0.3502044985863347  /  0.016882341997579584\n",
      "estimators:  10  prof:  5  | R2 mean / std:  0.4197182529926469  /  0.032559126040067284\n",
      "estimators:  10  prof:  10  | R2 mean / std:  0.3862264913707412  /  0.023428413803257275\n",
      "estimators:  100  prof:  1  | R2 mean / std:  0.3322910328148504  /  0.03404655779236188\n",
      "estimators:  100  prof:  5  | R2 mean / std:  0.42629546721514533  /  0.034997651912005295\n",
      "estimators:  100  prof:  10  | R2 mean / std:  0.42737615503239595  /  0.035434549330450295\n",
      "estimators:  1000  prof:  1  | R2 mean / std:  0.3357152476116722  /  0.03640265449537399\n",
      "estimators:  1000  prof:  5  | R2 mean / std:  0.4301173254803366  /  0.03613580695674186\n",
      "estimators:  1000  prof:  10  | R2 mean / std:  0.42297283296025306  /  0.03825792367336403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for n_est in [10,100,1000]:\n",
    "    for prof in [1,5,10]:\n",
    "        rf = RandomForestRegressor(n_estimators=n_est, max_depth=prof)\n",
    "        cvres = cross_val_score(estimator=rf, X = Xtrain, y = ytrain, cv = 3, scoring='r2')\n",
    "        print(\"estimators: \", n_est, \" prof: \", prof, \" | R2 mean / std: \", cvres.mean(), ' / ', cvres.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos, com algum trabalho, escolher o melhor modelo.\n",
    "\n",
    "Se quisermos testar mais parâmetros, podemos aumentar nosso loop... mais isso vai ficando cada vez mais complicado.\n",
    "\n",
    "A proposta do __grid-search__ é justamente fazer isso de forma mais automática!\n",
    "\n",
    "Podemos importar a função GridSearchCV do módulo model_selection do sklearn e usá-la para isso. \n",
    "Na prática, precisamos definir um __estimador base__ para o grid. Além disso, precisamos definir um __dicionário de parâmetros__ a ser testado. Ainda, definiremos a quantidade de folds para cross-validation e qual a métrica de performance que queremos otimizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando a função\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo o estimador base\n",
    "estimador_base = RandomForestRegressor()\n",
    "\n",
    "#definindo o dicionario de parâmetros do modelo\n",
    "params_RF = {\"n_estimators\":[10,1000], \"max_depth\":[2,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [2, 10], 'n_estimators': [10, 1000]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = estimador_base, \n",
    "                    param_grid = params_RF, \n",
    "                    scoring = 'r2', \n",
    "                    cv = 3)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [2, 10], 'n_estimators': [10, 1000]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#treinando os modelos no grid\n",
    "grid.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objeto \"grid\", após o treinamento acima, conterá várias informações muito relevantes. \n",
    "\n",
    "__1- \"best_params_\":__ retorna os melhores parâmetros, de acordo com a métrica de performance avaliada na cross-validation;\n",
    "\n",
    "__1- \"best_score_\":__ retorna o melhor score - métrica de performance - nos dados de validação;\n",
    "\n",
    "__1- \"best_estimator_\":__ retorna o melhor modelo, já treinado;\n",
    "\n",
    "__1- \"cv_results_\":__ retorna uma visão geral dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4225005250722306"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_estimators=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02327029, 1.33078766, 0.01695267, 1.69912283]),\n",
       " 'std_fit_time': array([1.52873314e-02, 2.50454940e-02, 4.70973091e-06, 2.36371525e-02]),\n",
       " 'mean_score_time': array([0.00165272, 0.0704778 , 0.00131631, 0.09308179]),\n",
       " 'std_score_time': array([0.00046619, 0.00417922, 0.0004503 , 0.0098306 ]),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 10, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 1000, 10, 1000],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 2, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'n_estimators': 1000},\n",
       "  {'max_depth': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'n_estimators': 1000}],\n",
       " 'split0_test_score': array([0.32474531, 0.35100446, 0.3206056 , 0.37089418]),\n",
       " 'split1_test_score': array([0.44905111, 0.44919614, 0.36595797, 0.44955746]),\n",
       " 'split2_test_score': array([0.45587826, 0.42937704, 0.40864926, 0.44704993]),\n",
       " 'mean_test_score': array([0.40989156, 0.40985921, 0.36507094, 0.42250053]),\n",
       " 'std_test_score': array([0.06027197, 0.04239584, 0.03594915, 0.03650555]),\n",
       " 'rank_test_score': array([2, 3, 4, 1])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercício 1:__ Utilizando o dataset abaixo, faça um grid_search com KNN's, Random Forests e GradientBoostings e retorne o melhor modelo de cada tipo.\n",
    "\n",
    "__Obs.:__ Lembre-se de fazer um pré-processamento nos dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>idade_mediana_das_casas</th>\n",
       "      <th>total_comodos</th>\n",
       "      <th>total_quartos</th>\n",
       "      <th>populacao</th>\n",
       "      <th>familias</th>\n",
       "      <th>salario_mediano</th>\n",
       "      <th>preco_mediano_das_casas</th>\n",
       "      <th>proximidade_ao_mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>PERTO DA BAÍA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>PERTO DA BAÍA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>PERTO DA BAÍA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>PERTO DA BAÍA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>PERTO DA BAÍA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  idade_mediana_das_casas  total_comodos  total_quartos  \\\n",
       "0    -122.23     37.88                     41.0          880.0          129.0   \n",
       "1    -122.22     37.86                     21.0         7099.0         1106.0   \n",
       "2    -122.24     37.85                     52.0         1467.0          190.0   \n",
       "3    -122.25     37.85                     52.0         1274.0          235.0   \n",
       "4    -122.25     37.85                     52.0         1627.0          280.0   \n",
       "\n",
       "   populacao  familias  salario_mediano  preco_mediano_das_casas  \\\n",
       "0      322.0     126.0           8.3252                 452600.0   \n",
       "1     2401.0    1138.0           8.3014                 358500.0   \n",
       "2      496.0     177.0           7.2574                 352100.0   \n",
       "3      558.0     219.0           5.6431                 341300.0   \n",
       "4      565.0     259.0           3.8462                 342200.0   \n",
       "\n",
       "  proximidade_ao_mar  \n",
       "0      PERTO DA BAÍA  \n",
       "1      PERTO DA BAÍA  \n",
       "2      PERTO DA BAÍA  \n",
       "3      PERTO DA BAÍA  \n",
       "4      PERTO DA BAÍA  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preco_mediano_das_casas é a variável target\n",
    "df = pd.read_csv(\"preco_casas.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude                    0\n",
      "latitude                     0\n",
      "idade_mediana_das_casas      0\n",
      "total_comodos                0\n",
      "total_quartos              207\n",
      "populacao                    0\n",
      "familias                     0\n",
      "salario_mediano              0\n",
      "preco_mediano_das_casas      0\n",
      "proximidade_ao_mar           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de nulos: 0.1003%\n"
     ]
    }
   ],
   "source": [
    "print('Percentual de nulos:', str(round((df.total_quartos.isnull().sum()/df.size)*100,4))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude                  0\n",
       "latitude                   0\n",
       "idade_mediana_das_casas    0\n",
       "total_comodos              0\n",
       "total_quartos              0\n",
       "populacao                  0\n",
       "familias                   0\n",
       "salario_mediano            0\n",
       "preco_mediano_das_casas    0\n",
       "proximidade_ao_mar         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separacao_variaveis(df):\n",
    "    \n",
    "    variavel_categorica = []\n",
    "    variavel_numerica = []\n",
    "    \n",
    "    for variavel in df.columns:\n",
    "        try:\n",
    "            df[variavel].sum() / 2 #Se não resultar em um erro, a coluna será do tipo numérica\n",
    "            variavel_numerica.append(variavel)\n",
    "            \n",
    "        except:\n",
    "            variavel_categorica.append(variavel) #Em caso de erro, será do tipo categórica\n",
    "    return variavel_categorica, variavel_numerica\n",
    "\n",
    "\n",
    "def tratamento_variaveis(df,\n",
    "                         variavel_categorica,\n",
    "                         variavel_numerica,\n",
    "                         variavel_target,\n",
    "                         dataset_de_treino = True,\n",
    "                         cat_encoder = None, \n",
    "                         std_scaler = None, \n",
    "                         ):\n",
    "    \n",
    "    if dataset_de_treino:  \n",
    "        \n",
    "        #OHE\n",
    "        encoder = OneHotEncoder()\n",
    "        df_variavel_categorica = encoder.fit_transform(df[variavel_categorica]).toarray()\n",
    "\n",
    "        #Normalização\n",
    "        sc = StandardScaler()\n",
    "        df_variavel_numerica = sc.fit_transform(df[variavel_numerica])\n",
    "        \n",
    "        X, y =  np.c_[df_variavel_categorica, df_variavel_numerica], variavel_target.values\n",
    "\n",
    "        return X, y, encoder, sc\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #OHE\n",
    "        df_variavel_categorica = cat_encoder.transform(df[variavel_categorica]).toarray()\n",
    "        \n",
    "        #normalização\n",
    "        df_variavel_numerica = std_scaler.transform(df[variavel_numerica]) \n",
    "        \n",
    "        X, y =  np.c_[df_variavel_categorica, df_variavel_numerica], variavel_target.values\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['proximidade_ao_mar']\n",
      "\n",
      "['longitude', 'latitude', 'idade_mediana_das_casas', 'total_comodos', 'total_quartos', 'populacao', 'familias', 'salario_mediano', 'preco_mediano_das_casas']\n"
     ]
    }
   ],
   "source": [
    "variavel_categorica, variavel_numerica = separacao_variaveis(df=df)\n",
    "print(variavel_categorica)\n",
    "print()\n",
    "print(variavel_numerica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain, dftest = train_test_split(df, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15324, 14), (15324,), (15324, 10))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, ytrain, encoder_train, std_scaler = tratamento_variaveis(df = dftrain,\n",
    "                                                               variavel_categorica = variavel_categorica,\n",
    "                                                               variavel_numerica = variavel_numerica,\n",
    "                                                               variavel_target = dftrain.preco_mediano_das_casas,\n",
    "                                                               dataset_de_treino = True,\n",
    "                                                               cat_encoder = None, \n",
    "                                                               std_scaler = None, \n",
    "                                                              )\n",
    "Xtrain.shape, ytrain.shape, dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5109, 14), (5109,), (5109, 10))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest, ytest = tratamento_variaveis(df = dftest,\n",
    "                                    variavel_categorica = variavel_categorica,\n",
    "                                    variavel_numerica = variavel_numerica,\n",
    "                                    variavel_target = dftest.preco_mediano_das_casas,\n",
    "                                    dataset_de_treino = False,\n",
    "                                    cat_encoder = encoder_train, \n",
    "                                    std_scaler = std_scaler, \n",
    "                                   )\n",
    "Xtest.shape, ytest.shape, dftest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search para os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(X,y,estimador_base,params,metrica,cv):\n",
    "    \n",
    "    grid = GridSearchCV(estimator = estimador_base,\n",
    "                        param_grid = params, \n",
    "                        scoring = metrica, \n",
    "                        cv = cv\n",
    "                       )\n",
    "    \n",
    "    grid.fit(X,y)\n",
    "    \n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    best_score = grid_knn.best_score_\n",
    "    \n",
    "    cv_results = grid.cv_results_\n",
    "    \n",
    "    return best_params, best_score, cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo (em segundos) para execução:  40.12\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "best_params_knn, best_score_knn, cv_results_knn = grid(X = Xtrain, \n",
    "                                           y = ytrain,\n",
    "                                           estimador_base = KNeighborsRegressor(),\n",
    "                                           params = [{'n_neighbors': [2,5,10], 'weights': ['uniform','distance'],'p':[1,2,5]}],\n",
    "                                           metrica = 'r2',\n",
    "                                           cv = 3)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5, 'p': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732959583910256"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo (em segundos) para execução:  284.68\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "best_params_rf, best_score_rf, cv_results_rf = grid(X = Xtrain, \n",
    "                                                    y = ytrain,\n",
    "                                                    estimador_base = RandomForestRegressor(),\n",
    "                                                    params = [{\"n_estimators\":[10,100,1000], \n",
    "                                                               \"max_depth\":[2,5,10]}],\n",
    "                                                    metrica = 'r2',\n",
    "                                                    cv = 3)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732959583910256"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo (em segundos) para execução:  128.48\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "best_params_gbr, best_score_gbr, cv_results_gbr = grid(X = Xtrain, \n",
    "                                                       y = ytrain,\n",
    "                                                       estimador_base = GradientBoostingRegressor(), \n",
    "                                                       params = [{\"n_estimators\":[10,100], \n",
    "                                                                  \"max_depth\":[2,10],\n",
    "                                                                  \"learning_rate\": [0.1,0.01],\n",
    "                                                                  \"min_samples_split\": [2,10]}],\n",
    "                                                       metrica = 'r2',\n",
    "                                                       cv = 3)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732959583910256"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todos os modelos tiveram uma assertividade impressionante nos dados com mais de 97% de acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercício 2:__ Crie uma classe para comparar o grid_search dentre vários modelos distintos.\n",
    "    \n",
    "    \n",
    "Essa classe, gridSearchAll(), já está pré-desenvolvida no código abaixo. O exercício consiste de __completar essa classe.__ Para isso, crie o métodos fit_all, que irá treinar, usando grid_search, todos os grids que tenham sido pré-construídos e inseridos na classe.\n",
    "Ainda, a quantidade de folds para a validação cruzada no grid_search deve ser implementada no método construtor da classe, bem como qual a métrica de performance a ser avaliada. \n",
    "Finalmente, salve o melhor modelo de cada grid e tenha um método best_all_grid_models que retorna o melhor modelo dentre todos os grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gridSearchAll():\n",
    "    \n",
    "    def __init__(self,num_folds):\n",
    "        self.grid_models = []\n",
    "        self.scoring = 'r2'\n",
    "        self.num_folds = num_folds\n",
    "    \n",
    "    def insert_model(self, estimator_base, param_grid):\n",
    "        self.grid_models.append([estimator_base, param_grid])\n",
    "        \n",
    "    def fit_all(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.best_scores = {}\n",
    "        \n",
    "        for estimador, parametros in self.grid_models:\n",
    "            \n",
    "            grid = GridSearchCV(estimator = estimador,\n",
    "                        param_grid = parametros, \n",
    "                        scoring = self.scoring, \n",
    "                        cv = self.num_folds\n",
    "                               )\n",
    "    \n",
    "            grid.fit(X,y)\n",
    "            print('Modelo', str(estimador).replace('()',''),'treinado')\n",
    "            \n",
    "            self.best_scores.update({str(estimador).replace('()',''):[grid.best_score_,grid.best_params_]})\n",
    "        \n",
    "        return self.best_scores\n",
    "    \n",
    "    def best_all_grid_models(self, best_scores):\n",
    "        x = max(best_scores[i] for i in best_scores)\n",
    "        print('A melhor modelo foi o', max(best_score, key=best_score.get), 'com',str(x[0]*100)+'% de acurácia,\\n tendo como parâmetros',x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercício 3:__ Usando a classe criada, analise novamente os modelos criados no exercício 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd = gridSearchAll(num_folds = 3)\n",
    "\n",
    "gd.grid_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RandomForestRegressor(),\n",
       "  [{'n_estimators': [10, 1000], 'max_depth': [2, 10]}]]]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parâmetros Random Forest\n",
    "\n",
    "params_RF = [{\"n_estimators\":[10,1000], \n",
    "              \"max_depth\":[2,10]}]\n",
    "\n",
    "gd.insert_model(estimator_base = RandomForestRegressor(), param_grid = params_RF)\n",
    "\n",
    "gd.grid_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RandomForestRegressor(),\n",
       "  [{'n_estimators': [10, 1000], 'max_depth': [2, 10]}]],\n",
       " [KNeighborsRegressor(),\n",
       "  [{'n_neighbors': [2, 10], 'weights': ['uniform', 'distance'], 'p': [1, 5]}]]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros KNN Regressor\n",
    "\n",
    "paramsKNN = [{'n_neighbors': [2,10],\n",
    "              'weights': ['uniform','distance'],\n",
    "              'p':[1,5]}]\n",
    "\n",
    "gd.insert_model(estimator_base = KNeighborsRegressor(), param_grid = paramsKNN)\n",
    "\n",
    "gd.grid_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RandomForestRegressor(),\n",
       "  [{'n_estimators': [10, 1000], 'max_depth': [2, 10]}]],\n",
       " [KNeighborsRegressor(),\n",
       "  [{'n_neighbors': [2, 10], 'weights': ['uniform', 'distance'], 'p': [1, 5]}]],\n",
       " [GradientBoostingRegressor(),\n",
       "  [{'n_estimators': [10, 100],\n",
       "    'max_depth': [2, 10],\n",
       "    'learning_rate': [0.1, 0.01],\n",
       "    'min_samples_split': [2, 10]}]]]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros GradientBoostings\n",
    "\n",
    "paramsGB = [{\"n_estimators\":[10,100], \n",
    "           \"max_depth\":[2,10],\n",
    "           \"learning_rate\": [0.1,0.01],\n",
    "           \"min_samples_split\": [2,10]}]\n",
    "\n",
    "gd.insert_model(estimator_base = GradientBoostingRegressor(), param_grid = paramsGB)\n",
    "\n",
    "gd.grid_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo RandomForestRegressor treinado\n",
      "Modelo KNeighborsRegressor treinado\n",
      "Modelo GradientBoostingRegressor treinado\n",
      "tempo (em segundos) para execução:  381.2\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "best_score = gd.fit_all(Xtrain,ytrain)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestRegressor': [0.9999980238935642,\n",
       "  {'max_depth': 10, 'n_estimators': 1000}],\n",
       " 'KNeighborsRegressor': [0.9714558927049305,\n",
       "  {'n_neighbors': 10, 'p': 5, 'weights': 'distance'}],\n",
       " 'GradientBoostingRegressor': [0.9999995722571619,\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100}]}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor modelo foi o GradientBoostingRegressor com 99.99995722571619% de acurácia,\n",
      " tendo como parâmetros {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "gd.best_all_grid_models(best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
