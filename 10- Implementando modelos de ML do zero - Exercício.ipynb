{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercício: Regressão Linear:\n",
    "__Parte 1:__\n",
    "\n",
    "1- Usando a função getData(), carregue os dados disponibilizados.\n",
    "\n",
    "2- Separe parte dos dados para o dataset de teste.\n",
    "\n",
    "3- Usando a metodologia de validação cruzada, teste diferentes parâmetros da regLinear - diferentes learning_rates e num_steps - para escolher a melhor combinação de parâmetros.\n",
    "\n",
    "4- Implemente a regressão linear do scikit-learn e compare os resultados obtidos.\n",
    "\n",
    "__Parte 2 (Introdução):__\n",
    "\n",
    "Para cada variável explicativa $X_1, .., X_5$, crie outras variáveis usando o __quadrado__ de cada um delas. Desta forma, o conjunto final será de 10 variáveis, em que:\n",
    "\n",
    "$X_6 = (X_1)^{2}$, $X_7 = (X_2)^{2}$, $X_8 = (X_3)^{2}$, $X_9 = (X_4)^{2}$, $X_{10} = (X_5)^{2}$.\n",
    "\n",
    "Ao treinarmos uma regressão linear com essas 10 variáveis, a predição é da forma:\n",
    "\n",
    "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2}$\n",
    "\n",
    "Como estamos usando o quadrado das variáveis explicativas, dizemos que temos um __modelo de regressão polinomial de grau 2__. Podemos ter variações deste modelo:\n",
    "\n",
    "-Podemos aumentar o grau: basta mudar a potência que elevamos as variáveis. Por exemplo, podemos incluir o __cubo__ das variáveis e termos um modelo polinomial de ordem 3.\n",
    "\n",
    "-Podemos ter __interações__ entre as variáveis: multiplicações entre as variáveis.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2} + \\theta_{11} \\cdot (X_1)^{3} + \\theta_{12} \\cdot V1 + \\theta_{13} \\cdot V2$,\n",
    "\n",
    "onde\n",
    "\n",
    "$V_1 = X_1 \\cdot X_2$ e $V_2 = (X_2)^{2} \\cdot X_4$\n",
    "\n",
    "__Parte 2 (Exercício):__\n",
    "\n",
    "1- Estude o link:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "em que é discutido como criar modelos polinomiais com o scikit-learn de forma detalhada.\n",
    "\n",
    "2- Repita os passos da primeira parte, mas agora considerando polinômios de graus 2 ou mais.\n",
    "\n",
    "3- Inclua regularização Ridge e Lasso nas análises e teste os resultados para diferentes parâmetros $\\alpha$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercício: Regressão Logística:\n",
    "\n",
    "__Parte 1:__\n",
    "\n",
    "Crie uma classe regLogistica para treinar o modelo de regressão logística. Essa classe deve ser usada para problemas de classificação binária, cuja variável target assume os valores: 0 (classe negativa) e 1 (classe positiva).\n",
    "\n",
    "O método construtor dessa classe deve possuir 3 parâmetros: learning_rate, num_steps e limiar.\n",
    "\n",
    "Os outros médotos devem ser:\n",
    "\n",
    "    - médoto fit: para treinar o modelo - usando gradient descent\n",
    "    \n",
    "    - médoto predict_proba: para retornar a probabilidade da classe 1\n",
    "    \n",
    "    - médoto predict: retornar a classe predita: 0 ou 1 - dependente do limiar\n",
    "    \n",
    "__Parte 2:__\n",
    "\n",
    "Usando a função getData2(), carregue o dataset disponibilizado.\n",
    "\n",
    "Use a regLogistica, classe criada na parte 1 do exercício, para treinar modelos nestes dados. Use validação cruzada para seleção dos parâmetros. Considere diferentes métricas de classificação e justifique as escolhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_friedman1, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Regressão Linear:\n",
    "#### Parte 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para acessar os dados do exercício 1\n",
    "\n",
    "def getData():\n",
    "    X, y = make_friedman1(n_samples = 10000, n_features = 5, noise = 5, random_state = 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
      " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
      " [0.79172504 0.52889492 0.56804456 0.92559664 0.07103606]\n",
      " [0.0871293  0.0202184  0.83261985 0.77815675 0.87001215]\n",
      " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]\n",
      " [0.63992102 0.14335329 0.94466892 0.52184832 0.41466194]\n",
      " [0.26455561 0.77423369 0.45615033 0.56843395 0.0187898 ]\n",
      " [0.6176355  0.61209572 0.616934   0.94374808 0.6818203 ]\n",
      " [0.3595079  0.43703195 0.6976312  0.06022547 0.66676672]\n",
      " [0.67063787 0.21038256 0.1289263  0.31542835 0.36371077]]\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "[[15.28814034]\n",
      " [21.53563265]\n",
      " [15.33477388]\n",
      " [18.80973929]\n",
      " [16.17485067]\n",
      " [20.57416088]\n",
      " [ 6.39920803]\n",
      " [21.80022823]\n",
      " [ 3.90210375]\n",
      " [ 5.41205623]]\n"
     ]
    }
   ],
   "source": [
    "X,y = getData()\n",
    "\n",
    "print(X[:10])\n",
    "\n",
    "print('\\n------------------------------------------------------------------\\n')\n",
    "\n",
    "print(y[:10].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5) (10000,)\n",
      "(7500, 5) (7500,)\n",
      "(2500, 5) (2500,)\n"
     ]
    }
   ],
   "source": [
    "#Será separado 25% dos dados para teste\n",
    "\n",
    "Xtrain, Xtest,ytrain,ytest = train_test_split(X,y, test_size = 0.25, random_state = 0)\n",
    "print(X.shape,y.shape)\n",
    "print(Xtrain.shape,ytrain.shape)\n",
    "print(Xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classe regLinear para exercício\n",
    "\n",
    "class regLinear():\n",
    "    \n",
    "    def __init__(self, learning_rate, num_steps):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_steps = num_steps\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        y = y.reshape(-1,1)\n",
    "        m = X.shape[0] \n",
    "        k = X.shape[1] \n",
    "        theta = np.random.randn(k+1,1) \n",
    "        X_b = np.c_[np.ones((m, 1)), X] \n",
    "        for step in range(self.num_steps):\n",
    "            gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "            theta = theta - self.learning_rate * gradients\n",
    "        self.theta_final = theta\n",
    "        #print(\"modelo treinado.\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        X_b = np.c_[np.ones((m, 1)), X]\n",
    "        preds = X_b.dot(self.theta_final)\n",
    "        return preds.reshape(-1,)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regLinear_comparacao(num_steps,learning_rate,classificador_comparacao,Xtrain,ytrain,Xtest,ytest):\n",
    "    \n",
    "    num_steps=num_steps\n",
    "    learning_rate=learning_rate\n",
    "    classificador = classificador_comparacao\n",
    "    classificador.fit(Xtrain, ytrain)\n",
    "    classificador_predict_train = classificador.predict(Xtrain)\n",
    "    classificador_predict_test = classificador.predict(Xtest)\n",
    "    nome_classificador = str(classificador_comparacao).replace('()','')\n",
    "\n",
    "    for num_steps, learning_rate in zip(num_steps,learning_rate):\n",
    "\n",
    "        rg = regLinear(learning_rate = learning_rate, num_steps = num_steps)\n",
    "        rg.fit(Xtrain, ytrain)\n",
    "        rg_predict_train = rg.predict(Xtrain)\n",
    "        rg_predict_test = rg.predict(Xtest)\n",
    "        \n",
    "        comparacao_treino = np.c_[np.round_(classificador_predict_train[:10],4), #Predições do classificador\n",
    "                                  np.round_(rg_predict_train[:10],4), #Predições da regLinear\n",
    "                                  np.round_(classificador_predict_train[:10],4)-np.round_(rg_predict_train[:10],4), #diff\n",
    "                                  np.round_(ytrain[:10].reshape(-1,1),4) #Variável target\n",
    "                                 ]\n",
    "        \n",
    "        RMSE_treino = np.sqrt(mean_squared_error(y_true = ytrain, y_pred = classificador_predict_train))\n",
    "            \n",
    "        comparacao_teste = np.c_[np.round_(classificador_predict_test[:10],4), \n",
    "                                 np.round_(rg_predict_test[:10],4),\n",
    "                                 np.round_(classificador_predict_test[:10],4)-np.round_(rg_predict_test[:10],4),\n",
    "                                 np.round_(ytest[:10].reshape(-1,1),4)\n",
    "                                ]\n",
    "        \n",
    "        RMSE_teste = np.sqrt(mean_squared_error(y_true = ytest, y_pred = classificador_predict_test))\n",
    "       \n",
    "\n",
    "        print('Quantidade de passos:',num_steps)\n",
    "        print('Taxa de aprendizado:',learning_rate)\n",
    "        \n",
    "        print('\\nComparação dos resultados em dados de treino:')\n",
    "        print(nome_classificador,'x reglinear x Diferença x Variável Target\\n')\n",
    "        print(comparacao_treino)\n",
    "        print('\\nRMSE dos dados de treino:',RMSE_treino)\n",
    "        \n",
    "        print('\\n--------------------------------------------\\n')\n",
    "        \n",
    "        print('\\nComparação dos resultados em dados de teste:')\n",
    "        print(nome_classificador,'x reglinear x Diferença x Variável Target\\n')\n",
    "        print(comparacao_teste)\n",
    "        print('\\nRMSE dos dados de teste:',RMSE_teste,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de passos: 250\n",
      "Taxa de aprendizado: 0.1\n",
      "\n",
      "Comparação dos resultados em dados de treino:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[ 1.94989e+01  1.93850e+01  1.13900e-01  1.28066e+01]\n",
      " [ 1.12942e+01  1.12800e+01  1.42000e-02  1.32577e+01]\n",
      " [ 1.08702e+01  1.10888e+01 -2.18600e-01  1.25476e+01]\n",
      " [ 1.78540e+01  1.77759e+01  7.81000e-02  1.84473e+01]\n",
      " [ 9.64440e+00  1.00951e+01 -4.50700e-01 -1.77690e+00]\n",
      " [ 8.14170e+00  8.48790e+00 -3.46200e-01  4.01050e+00]\n",
      " [ 1.33002e+01  1.35038e+01 -2.03600e-01  1.83020e+01]\n",
      " [ 7.86290e+00  8.16790e+00 -3.05000e-01  1.49591e+01]\n",
      " [ 1.10141e+01  1.11852e+01 -1.71100e-01  6.50070e+00]\n",
      " [ 1.68789e+01  1.70013e+01 -1.22400e-01  2.17621e+01]]\n",
      "\n",
      "RMSE dos dados de treino: 5.5527435100835625\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "Comparação dos resultados em dados de teste:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[ 1.61365e+01  1.61335e+01  3.00000e-03  1.69377e+01]\n",
      " [ 1.33709e+01  1.33919e+01 -2.10000e-02  8.40610e+00]\n",
      " [ 1.89491e+01  1.87893e+01  1.59800e-01  3.49781e+01]\n",
      " [ 1.50555e+01  1.52085e+01 -1.53000e-01  1.96506e+01]\n",
      " [ 1.51366e+01  1.51185e+01  1.81000e-02  2.13983e+01]\n",
      " [ 1.48607e+01  1.47654e+01  9.53000e-02  1.22073e+01]\n",
      " [ 1.71198e+01  1.70815e+01  3.83000e-02  1.25481e+01]\n",
      " [ 1.03024e+01  1.06459e+01 -3.43500e-01  8.99540e+00]\n",
      " [ 1.59216e+01  1.59866e+01 -6.50000e-02  1.87900e+01]\n",
      " [ 2.27659e+01  2.21972e+01  5.68700e-01  2.95745e+01]]\n",
      "\n",
      "RMSE dos dados de teste: 5.544056801551662 \n",
      "\n",
      "Quantidade de passos: 500\n",
      "Taxa de aprendizado: 0.2\n",
      "\n",
      "Comparação dos resultados em dados de treino:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[ 1.94989e+01  1.94987e+01  2.00000e-04  1.28066e+01]\n",
      " [ 1.12942e+01  1.12938e+01  4.00000e-04  1.32577e+01]\n",
      " [ 1.08702e+01  1.08711e+01 -9.00000e-04  1.25476e+01]\n",
      " [ 1.78540e+01  1.78538e+01  2.00000e-04  1.84473e+01]\n",
      " [ 9.64440e+00  9.64650e+00 -2.10000e-03 -1.77690e+00]\n",
      " [ 8.14170e+00  8.14300e+00 -1.30000e-03  4.01050e+00]\n",
      " [ 1.33002e+01  1.33012e+01 -1.00000e-03  1.83020e+01]\n",
      " [ 7.86290e+00  7.86400e+00 -1.10000e-03  1.49591e+01]\n",
      " [ 1.10141e+01  1.10148e+01 -7.00000e-04  6.50070e+00]\n",
      " [ 1.68789e+01  1.68797e+01 -8.00000e-04  2.17621e+01]]\n",
      "\n",
      "RMSE dos dados de treino: 5.5527435100835625\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "Comparação dos resultados em dados de teste:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[ 1.61365e+01  1.61367e+01 -2.00000e-04  1.69377e+01]\n",
      " [ 1.33709e+01  1.33710e+01 -1.00000e-04  8.40610e+00]\n",
      " [ 1.89491e+01  1.89486e+01  5.00000e-04  3.49781e+01]\n",
      " [ 1.50555e+01  1.50563e+01 -8.00000e-04  1.96506e+01]\n",
      " [ 1.51366e+01  1.51365e+01  1.00000e-04  2.13983e+01]\n",
      " [ 1.48607e+01  1.48602e+01  5.00000e-04  1.22073e+01]\n",
      " [ 1.71198e+01  1.71198e+01  0.00000e+00  1.25481e+01]\n",
      " [ 1.03024e+01  1.03040e+01 -1.60000e-03  8.99540e+00]\n",
      " [ 1.59216e+01  1.59220e+01 -4.00000e-04  1.87900e+01]\n",
      " [ 2.27659e+01  2.27635e+01  2.40000e-03  2.95745e+01]]\n",
      "\n",
      "RMSE dos dados de teste: 5.544056801551662 \n",
      "\n",
      "Quantidade de passos: 750\n",
      "Taxa de aprendizado: 0.3\n",
      "\n",
      "Comparação dos resultados em dados de treino:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[19.4989 19.4989  0.     12.8066]\n",
      " [11.2942 11.2942  0.     13.2577]\n",
      " [10.8702 10.8702  0.     12.5476]\n",
      " [17.854  17.854   0.     18.4473]\n",
      " [ 9.6444  9.6444  0.     -1.7769]\n",
      " [ 8.1417  8.1417  0.      4.0105]\n",
      " [13.3002 13.3002  0.     18.302 ]\n",
      " [ 7.8629  7.8629  0.     14.9591]\n",
      " [11.0141 11.0141  0.      6.5007]\n",
      " [16.8789 16.8789  0.     21.7621]]\n",
      "\n",
      "RMSE dos dados de treino: 5.5527435100835625\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "Comparação dos resultados em dados de teste:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[16.1365 16.1365  0.     16.9377]\n",
      " [13.3709 13.3709  0.      8.4061]\n",
      " [18.9491 18.9491  0.     34.9781]\n",
      " [15.0555 15.0555  0.     19.6506]\n",
      " [15.1366 15.1366  0.     21.3983]\n",
      " [14.8607 14.8607  0.     12.2073]\n",
      " [17.1198 17.1198  0.     12.5481]\n",
      " [10.3024 10.3024  0.      8.9954]\n",
      " [15.9216 15.9216  0.     18.79  ]\n",
      " [22.7659 22.7659  0.     29.5745]]\n",
      "\n",
      "RMSE dos dados de teste: 5.544056801551662 \n",
      "\n",
      "Quantidade de passos: 1000\n",
      "Taxa de aprendizado: 0.4\n",
      "\n",
      "Comparação dos resultados em dados de treino:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[19.4989 19.4989  0.     12.8066]\n",
      " [11.2942 11.2942  0.     13.2577]\n",
      " [10.8702 10.8702  0.     12.5476]\n",
      " [17.854  17.854   0.     18.4473]\n",
      " [ 9.6444  9.6444  0.     -1.7769]\n",
      " [ 8.1417  8.1417  0.      4.0105]\n",
      " [13.3002 13.3002  0.     18.302 ]\n",
      " [ 7.8629  7.8629  0.     14.9591]\n",
      " [11.0141 11.0141  0.      6.5007]\n",
      " [16.8789 16.8789  0.     21.7621]]\n",
      "\n",
      "RMSE dos dados de treino: 5.5527435100835625\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "Comparação dos resultados em dados de teste:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[16.1365 16.1365  0.     16.9377]\n",
      " [13.3709 13.3709  0.      8.4061]\n",
      " [18.9491 18.9491  0.     34.9781]\n",
      " [15.0555 15.0555  0.     19.6506]\n",
      " [15.1366 15.1366  0.     21.3983]\n",
      " [14.8607 14.8607  0.     12.2073]\n",
      " [17.1198 17.1198  0.     12.5481]\n",
      " [10.3024 10.3024  0.      8.9954]\n",
      " [15.9216 15.9216  0.     18.79  ]\n",
      " [22.7659 22.7659  0.     29.5745]]\n",
      "\n",
      "RMSE dos dados de teste: 5.544056801551662 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps=[250,500,750,1000]\n",
    "learning_rate=[0.1, 0.2,0.3, 0.4]\n",
    "\n",
    "regLinear_comparacao(num_steps=num_steps,\n",
    "                     learning_rate=learning_rate,\n",
    "                     classificador_comparacao=LinearRegression(),\n",
    "                     Xtrain=Xtrain,\n",
    "                     ytrain=ytrain,\n",
    "                     Xtest=Xtest,\n",
    "                     ytest=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A regLinear se comportou bem melhor com step a partir de 750 e taxa de aprendizado a partir de 0,3. Nesse contexto, podemos testar step = 1000 com uma taxa menor (0,1) e ver como o modelo se comporta. O RMSE também ficou alinhado com o parâmetro noise=5.0 do make_friedman1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de passos: 1000\n",
      "Taxa de aprendizado: 0.1\n",
      "\n",
      "Comparação dos resultados em dados de treino:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[ 1.94989e+01  1.94987e+01  2.00000e-04  1.28066e+01]\n",
      " [ 1.12942e+01  1.12938e+01  4.00000e-04  1.32577e+01]\n",
      " [ 1.08702e+01  1.08710e+01 -8.00000e-04  1.25476e+01]\n",
      " [ 1.78540e+01  1.78538e+01  2.00000e-04  1.84473e+01]\n",
      " [ 9.64440e+00  9.64620e+00 -1.80000e-03 -1.77690e+00]\n",
      " [ 8.14170e+00  8.14280e+00 -1.10000e-03  4.01050e+00]\n",
      " [ 1.33002e+01  1.33011e+01 -9.00000e-04  1.83020e+01]\n",
      " [ 7.86290e+00  7.86390e+00 -1.00000e-03  1.49591e+01]\n",
      " [ 1.10141e+01  1.10147e+01 -6.00000e-04  6.50070e+00]\n",
      " [ 1.68789e+01  1.68796e+01 -7.00000e-04  2.17621e+01]]\n",
      "\n",
      "RMSE dos dados de treino: 5.5527435100835625\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "Comparação dos resultados em dados de teste:\n",
      "LinearRegression x reglinear x Diferença x Variável Target\n",
      "\n",
      "[[ 1.61365e+01  1.61366e+01 -1.00000e-04  1.69377e+01]\n",
      " [ 1.33709e+01  1.33710e+01 -1.00000e-04  8.40610e+00]\n",
      " [ 1.89491e+01  1.89486e+01  5.00000e-04  3.49781e+01]\n",
      " [ 1.50555e+01  1.50562e+01 -7.00000e-04  1.96506e+01]\n",
      " [ 1.51366e+01  1.51365e+01  1.00000e-04  2.13983e+01]\n",
      " [ 1.48607e+01  1.48602e+01  5.00000e-04  1.22073e+01]\n",
      " [ 1.71198e+01  1.71198e+01  0.00000e+00  1.25481e+01]\n",
      " [ 1.03024e+01  1.03038e+01 -1.40000e-03  8.99540e+00]\n",
      " [ 1.59216e+01  1.59219e+01 -3.00000e-04  1.87900e+01]\n",
      " [ 2.27659e+01  2.27638e+01  2.10000e-03  2.95745e+01]]\n",
      "\n",
      "RMSE dos dados de teste: 5.544056801551662 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps=[1000]\n",
    "learning_rate=[0.1]\n",
    "\n",
    "regLinear_comparacao(num_steps=num_steps,\n",
    "                     learning_rate=learning_rate,\n",
    "                     classificador_comparacao=LinearRegression(),\n",
    "                     Xtrain=Xtrain,\n",
    "                     ytrain=ytrain,\n",
    "                     Xtest=Xtest,\n",
    "                     ytest=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Os resultados da regLinear foram praticamente idênticos ao da regressão logística com os parâmetros acima!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36453906 0.37397915 0.3635744  0.38055211 0.37465289]\n",
      "media:  0.3714595229612249\n",
      "desvio padrão:  0.006469764437639058\n"
     ]
    }
   ],
   "source": [
    "cv_lin_reg = cross_val_score(estimator = LinearRegression(), \n",
    "                             X = Xtrain, \n",
    "                             y = ytrain, \n",
    "                             cv = 5, \n",
    "                             scoring = 'r2')\n",
    "print(cv_lin_reg)\n",
    "print('media: ', cv_lin_reg.mean())\n",
    "print('desvio padrão: ', cv_lin_reg.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Regressão Linear:\n",
    "#### Parte 2 - Regressão polinomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyFit(X, y, grau, base_model,base_model_name):\n",
    "\n",
    "    for grau in grau:\n",
    "        \n",
    "        polybig_features = PolynomialFeatures(degree = grau, include_bias = False)\n",
    "        std_scaler = StandardScaler()\n",
    "        basemodel = base_model\n",
    "    \n",
    "        #criando um pipeline: sequencia de execução de passos\n",
    "        polynomial_regression = Pipeline([\n",
    "                (\"poly_features\", polybig_features),\n",
    "                (\"std_scaler\", std_scaler),\n",
    "                (\"base_model_name\", base_model),\n",
    "            ])\n",
    "    \n",
    "        polyFit = polynomial_regression.fit(X, y)\n",
    "        \n",
    "        print(\"Regularização:\",Model_name)\n",
    "    \n",
    "        print(\"grau: \", grau)\n",
    "\n",
    "        polyFit.predict(X)\n",
    "\n",
    "        print(\"RMSE:\")\n",
    "        print(np.sqrt(np.mean(np.square(y - polyFit.predict(X)))))\n",
    "        print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização Ridge em dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1\n",
      "Regularização: Ridge\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.158800384287972\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.903875114891525\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.6995005165153945\n",
      "------------------------------------------------\n",
      "Alpha: 0.01\n",
      "Regularização: Ridge\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.1588002758506075\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.896345642636893\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.609064755944324\n",
      "------------------------------------------------\n",
      "Alpha: 0.001\n",
      "Regularização: Ridge\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.158800274765201\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.895380215627292\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.501813372896098\n",
      "------------------------------------------------\n",
      "tempo (em segundos) para execução:  10.77\n"
     ]
    }
   ],
   "source": [
    "grau = [2,5,10]\n",
    "Model_name= 'Ridge'\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for alpha in [0.1,0.01,0.001]:\n",
    "    \n",
    "    print(\"Alpha:\",alpha)\n",
    "    polyFit(X = Xtrain,\n",
    "            y = ytrain,\n",
    "            grau = grau,\n",
    "            base_model = Ridge(alpha = alpha),\n",
    "            base_model_name = Model_name\n",
    "       )\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização Ridge em dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1\n",
      "Regularização: Ridge\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.155017888946525\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.8308845584602915\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.337394958967313\n",
      "------------------------------------------------\n",
      "Alpha: 0.01\n",
      "Regularização: Ridge\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.1550168876582845\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.7953502841510005\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.088903782383004\n",
      "------------------------------------------------\n",
      "Alpha: 0.001\n",
      "Regularização: Ridge\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.155016877615181\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.783730451422006\n",
      "------------------------------------------------\n",
      "Regularização: Ridge\n",
      "grau:  10\n",
      "RMSE:\n",
      "3.7851623331572615\n",
      "------------------------------------------------\n",
      "tempo (em segundos) para execução:  3.56\n"
     ]
    }
   ],
   "source": [
    "grau = [2,5,10]\n",
    "Model_name= 'Ridge'\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for alpha in [0.1,0.01,0.001]:\n",
    "    \n",
    "    print(\"Alpha:\",alpha)\n",
    "    polyFit(X = Xtest,\n",
    "            y = ytest,\n",
    "            grau = grau,\n",
    "            base_model = Ridge(alpha = alpha),\n",
    "            base_model_name = Model_name\n",
    "       )\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização Lasso em dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1\n",
      "Regularização: Lasso\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.347414476589604\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  5\n",
      "RMSE:\n",
      "5.047841298242992\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  10\n",
      "RMSE:\n",
      "5.055161150236008\n",
      "------------------------------------------------\n",
      "Alpha: 0.01\n",
      "Regularização: Lasso\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.161218564323897\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.9687394630443755\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.946128240377529\n",
      "------------------------------------------------\n",
      "Alpha: 0.001\n",
      "Regularização: Lasso\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.158838965255326\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.9381121242394395\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.876753769114236\n",
      "------------------------------------------------\n",
      "tempo (em segundos) para execução:  49.16\n"
     ]
    }
   ],
   "source": [
    "grau = [2,5,10]\n",
    "Model_name= 'Lasso'\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for alpha in [0.1,0.01,0.001]:\n",
    "    \n",
    "    print(\"Alpha:\",alpha)\n",
    "    polyFit(X = Xtrain,\n",
    "            y = ytrain,\n",
    "            grau = grau,\n",
    "            base_model = Lasso(alpha = alpha),\n",
    "            base_model_name = Model_name\n",
    "       )\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização Ridge em dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1\n",
      "Regularização: Lasso\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.34874980218386\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  5\n",
      "RMSE:\n",
      "5.074760764493081\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  10\n",
      "RMSE:\n",
      "5.066938193727527\n",
      "------------------------------------------------\n",
      "Alpha: 0.01\n",
      "Regularização: Lasso\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.158047115766565\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.964678114797044\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.895090229976122\n",
      "------------------------------------------------\n",
      "Alpha: 0.001\n",
      "Regularização: Lasso\n",
      "grau:  2\n",
      "RMSE:\n",
      "5.155054267158118\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  5\n",
      "RMSE:\n",
      "4.905463617081603\n",
      "------------------------------------------------\n",
      "Regularização: Lasso\n",
      "grau:  10\n",
      "RMSE:\n",
      "4.6950685004706685\n",
      "------------------------------------------------\n",
      "tempo (em segundos) para execução:  15.05\n"
     ]
    }
   ],
   "source": [
    "grau = [2,5,10]\n",
    "Model_name= 'Lasso'\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for alpha in [0.1,0.01,0.001]:\n",
    "    \n",
    "    print(\"Alpha:\",alpha)\n",
    "    polyFit(X = Xtest,\n",
    "            y = ytest,\n",
    "            grau = grau,\n",
    "            base_model = Lasso(alpha = alpha),\n",
    "            base_model_name = Model_name\n",
    "       )\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"tempo (em segundos) para execução: \", np.round(t1-t0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Regressão Logística:\n",
    "#### Parte 1 - Criar uma classe para treinar dados em regressão logística::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regLogistica():\n",
    "    \n",
    "    def __init__(self, learning_rate, num_steps, limiar):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_steps = num_steps\n",
    "        self.limiar = limiar\n",
    "        \n",
    "    def sigmoid(self, t):\n",
    "        return 1 / (1 + np.exp(-t))\n",
    "       \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_b = np.c_[np.ones(X.shape[0]), X]\n",
    "        theta = np.random.randn(X_b.shape[1],1) #instanciando um vetor de parâmetros theta aleatório\n",
    "        \n",
    "        for step in range(self.num_steps):\n",
    "\n",
    "            #calculando a probabilidade \n",
    "            yscores = sigmoid(X_b.dot(theta))\n",
    "\n",
    "            #calculando o gradiente da Log Loss\n",
    "            gradient = X_b.T.dot(yscores - y)\n",
    "\n",
    "            #atualizando os pesos\n",
    "            theta = theta - self.learning_rate * gradient\n",
    "\n",
    "        self.theta_final = theta\n",
    "              \n",
    "    def predict_proba(self,theta_final):\n",
    "        t = X_b.dot(theta_final)\n",
    "        yscores = sigmoid(t)\n",
    "        ypred = np.where(yscores > limiar, 1, 0)\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Regressão Logística:\n",
    "#### Parte 2 - Usar a classe criada acima para treinar os dados carregados abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para acessar os dados do exercício 2\n",
    "\n",
    "def getData2():\n",
    "    X, y = make_classification(n_classes=2, n_features=5, n_samples=10000, random_state = 0)\n",
    "    y= y.reshape(-1,1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.82380715 -0.59163837  0.13041933 -0.40345475  1.16360785]\n",
      " [ 0.7091986   0.60606127 -0.37678226  0.39654936 -1.15961369]\n",
      " [ 1.61194498  0.36486859  1.91264129  0.38601731 -0.31972146]\n",
      " [-0.87521758  0.03070064 -1.66414467 -0.09315833  0.30731465]\n",
      " [-1.32532555  0.19953765 -2.9384829  -0.06318708 -0.96281507]\n",
      " [-0.97739632 -1.14675541  1.37104493 -0.70502371 -0.07881854]\n",
      " [-0.38160656 -1.07066645  2.23867692 -0.59225403 -1.58645395]\n",
      " [ 1.3759365   1.29166811 -1.04773872  0.8282992  -0.61000978]\n",
      " [ 1.29969415  0.56763584  0.79442277  0.45038871 -1.26101667]\n",
      " [ 0.43890899  0.55569056 -0.72705201  0.3373232  -0.55876158]]\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "X, y = getData2()\n",
    "\n",
    "print(X[:10])\n",
    "\n",
    "print('\\n------------------------------------------------------------------\\n')\n",
    "\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5) (10000, 1)\n",
      "(7500, 5) (7500, 1)\n",
      "(2500, 5) (2500, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest,ytrain,ytest = train_test_split(X,y, test_size = 0.25, random_state = 0)\n",
    "print(X.shape,y.shape)\n",
    "print(Xtrain.shape,ytrain.shape)\n",
    "print(Xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiar: 0.05\n",
      "Assertividade da regLogistica: 82.49%\n",
      "\n",
      "Limiar: 0.1\n",
      "Assertividade da regLogistica: 82.47%\n",
      "\n",
      "Limiar: 0.15\n",
      "Assertividade da regLogistica: 82.51%\n",
      "\n",
      "Limiar: 0.2\n",
      "Assertividade da regLogistica: 82.48%\n",
      "\n",
      "Limiar: 0.25\n",
      "Assertividade da regLogistica: 82.41%\n",
      "\n",
      "Limiar: 0.3\n",
      "Assertividade da regLogistica: 82.4%\n",
      "\n",
      "Limiar: 0.35\n",
      "Assertividade da regLogistica: 82.36%\n",
      "\n",
      "Limiar: 0.39999999999999997\n",
      "Assertividade da regLogistica: 82.39%\n",
      "\n",
      "Limiar: 0.44999999999999996\n",
      "Assertividade da regLogistica: 82.37%\n",
      "\n",
      "Limiar: 0.49999999999999994\n",
      "Assertividade da regLogistica: 82.43%\n",
      "\n",
      "Limiar: 0.5499999999999999\n",
      "Assertividade da regLogistica: 82.44%\n",
      "\n",
      "Limiar: 0.6\n",
      "Assertividade da regLogistica: 82.45%\n",
      "\n",
      "Limiar: 0.65\n",
      "Assertividade da regLogistica: 82.47%\n",
      "\n",
      "Limiar: 0.7\n",
      "Assertividade da regLogistica: 82.51%\n",
      "\n",
      "Limiar: 0.75\n",
      "Assertividade da regLogistica: 82.49%\n",
      "\n",
      "Limiar: 0.7999999999999999\n",
      "Assertividade da regLogistica: 82.45%\n",
      "\n",
      "Limiar: 0.85\n",
      "Assertividade da regLogistica: 82.35%\n",
      "\n",
      "Limiar: 0.9\n",
      "Assertividade da regLogistica: 82.35%\n",
      "\n",
      "Limiar: 0.95\n",
      "Assertividade da regLogistica: 82.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "limiares = np.linspace(0.05,0.95,19)\n",
    "\n",
    "for limiar in limiares:\n",
    "    rL = regLogistica(learning_rate=0.01,num_steps=100, limiar=limiar)\n",
    "    rL.fit(X=Xtrain, y=ytrain)\n",
    "    ypred = rL.predict_proba(theta_final)\n",
    "    \n",
    "    print(\"Limiar:\",limiar)\n",
    "    print(\"Assertividade da regLogistica:\",str(round(((ypred == ytrain).sum() / ypred.size)*100,2))+'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparação da classe regLogística com a Logistic Regression do SckitLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vimos que o comportamento dos resultados foi bem parecido ao variar os limiares, então para compararmos os resultados com o SckitLearn vamos manter o limiar padrão de 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg = logreg.fit(Xtrain, ytrain)\n",
    "logreg = logreg.predict(Xtrain).reshape(-1,1)\n",
    "\n",
    "rL = regLogistica(learning_rate=0.01,num_steps=100, limiar=0.5)\n",
    "rL.fit(X=Xtrain, y=ytrain)\n",
    "ypred = rL.predict_proba(theta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertividade da regLogistica: 82.31%\n",
      "Assertividade da Logistic Regression do Sklearn: 82.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"Assertividade da regLogistica:\",str(round(((ypred == ytrain).sum() / ypred.size)*100,2))+'%')\n",
    "print(\"Assertividade da Logistic Regression do Sklearn:\", str(round(((logreg == ytrain).sum() / logreg.size)*100,2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8230666666666666"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred = ytrain, y_true = ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros positivos: 3163\n",
      "Falsos positivos: 604\n",
      "Falsos negativos: 723\n",
      "Verdadeiros negativos: 3010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Verdadeiros positivos:\",confusion_matrix(y_true = ytrain, y_pred = ypred)[0,0])\n",
    "print(\"Falsos positivos:\",confusion_matrix(y_true = ytrain, y_pred = ypred)[0,1])\n",
    "print(\"Falsos negativos:\",confusion_matrix(y_true = ytrain, y_pred = ypred)[1,0])\n",
    "print(\"Verdadeiros negativos:\",confusion_matrix(y_true = ytrain, y_pred = ypred)[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Justificativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vimos em aula que somente a acurácia nem sempre é um bom sistema de classificação se olhada de forma isolada. Nesse contexto, a matriz de confusão é um reforço para a análise e comprovou a eficácia demonstrada pelo modelo através da acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
